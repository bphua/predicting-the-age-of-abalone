---
title: 'Group Project: T09; DS6'
author: '450132759, 450237777, 470315518, 470396894'
date: "October 5, 2018"
output: 
  prettydoc::html_pretty:
    theme: cayman # prettydoc theme
    highlight: null # syntax highlighting
---
<!-- Please run install.packages("prettydoc") and library(prettydoc) before knitting -->
<style>
@import url('https://fonts.googleapis.com/css?family=Roboto+Mono');
@import url('https://fonts.googleapis.com/css?family=Lato');
body{
  font-family: 'Lato' !important;
  font-size: 12pt;
}

code{
  font-family: 'Roboto Mono' !important;
  font-size: 12px;
}

pre{
  font-family: 'Roboto Mono' !important;
  font-size: 12px
}

td{
  font-family: Lato !important;
  font-size: 12pt;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = "center")
```

## Abstract
<!-- A one paragraph summary of what you set out to learn, and what you ended up finding. It should summarise the entire report. -->


## Introduction
<!-- A discussion of what questions you are trying to answer. -->


## Data Set
<!-- Describe details about how the data set was collected (if known) and the variables in the data set. -->

### Importing Data

```{r import}
data = read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data", sep = ",")
View(data)
library(tidyverse)
library(gridExtra)
glimpse(data)
```

### Cleaning 
```{r}
#install.packages("reshape")
library(reshape)
library(ggplot2)
new_names <- c("Sex", "Length", "Diameter", "Height", "Whole_weight", "Shucked_weight", "Viscera_weight", "Shell_weight", "Rings")

colnames(data) <- new_names

summary(data)

#Length, Diameter, Height in mm
#Weight in g

#Outliers
melt(data) %>%
  ggplot(aes(x = variable, y = value)) +
  geom_boxplot(outlier.size=2, outlier.colour='blue') + facet_wrap(~ variable, scales = 
  "free") 

#Remove Height = 0.515mm and 1.13mm as it is greater than Q3 + (1.5*IQR) = 0.24
new_data <- subset(data, data$Height < 0.5)
ggplot(new_data, aes(y = Height)) +
geom_boxplot(outlier.size=3, outlier.colour='blue')

#Remove measurements that equals to 0 as well as weight s.t. `Shucked weight` + `Viscera weight` + `Shell weight` > `Whole weight`
new_data %>% filter(Length, Diameter, Height, `Whole_weight`, `Shucked_weight`, `Viscera_weight`, `Shell_weight` == 0) %>% filter(`Shucked_weight` + `Viscera_weight` + `Shell_weight` > `Whole_weight`)
summary(new_data)

#Multivariate Normality
#install.packages("energy")
#install.packages("mvtnorm")
library(energy)
library(mvtnorm)
data_less_sex <- new_data %>% select(-Sex)
mvnorm.e(data_less_sex)

#install.packages("MVN")
library(MVN)
result <- mvn(data = data_less_sex, mvnTest = "dh")
result$multivariateNormality
result <- mvn(data = data_less_sex, mvnTest = "dh", univariatePlot = "histogram")

# check weights
data %>%
  mutate(sum_weight = Shell_weight + Viscera_weight + Shucked_weight) %>%
  summarise(bad = sum(sum_weight > Whole_weight)) 


```


## Analysis
<!-- Describe how you used multiple regression to analyse the data set. Specifically, you should discuss how you carried out the steps in analysis discussed in class, i.e., exploration of data to find an initial reasonable model, checking the model and changes to the model based on your checking of the model. -->
```{r}
# basic testing - to get a feel for things - not necessarily for preso or report

# some stats
data %>%
  group_by(Sex) %>%
  summarize(mean_wgt = mean(Whole_weight), mean_lenght = mean(Length), mean_rings = mean(Rings), min_rings = min(Rings), max_rings = max(Rings))

# correlation pairs:
library(GGally)
#ggpairs(data)   # function takes a long time to execute.

# how many of each sex, m/f/infant
data %>%
  group_by(Sex) %>%
  summarize(n = n())


# Full model 
full_model <- lm(Rings ~ ., data = data)
summary(full_model)
t(round(broom::glance(full_model), 2))


```

### Initial Analysis:

The first step is to determine an appropriate model for multiple regression of the data. We use the AIC model selection method in the backwards direction to achieve this. We begin with the full model and remove the least informative variable after every iteration. 
```{r}
# Initialise the full model under M0:
M1 = lm(Rings~.,data=data)

# Use backwards selection of AIC to determine which independent variables 
# would have a linear relationship with the Rings variable.
step.back.aic = step(M1,direction = "backward",trace=FALSE)

# Output our results.
drop1(step.back.aic,test = "F")
step.back.aic$coefficients

# Check if our assumptions for regression are valid.
library(ggfortify)
autoplot(step.back.aic,which = 1:2)
```

The model has determined that all the variables except for length has a relationship with the number of rings as we reject the null hypothesis of being no relationship because the p-value is smaller than the critical value. Interestingly enough, the degrees of freedom for sex is 2, meaning both infants and males have a relationship with the number of rings, but not females. 

### Assumptions and Transformation

However, issues arise when checking for the assumptions of regression. Firstly, observing the residual plot, the shape of the blue line indicates a non-linear relationship and violates the linearity assumption. Furthermore, the normality in the qqplot is questionable especially at the ends. Hence, transformation is required of the data, and we have chosen to take the log of the rings variable. 

```{r}
library(knitr)
# Now we take the inverse of ring values and add it to the original dataset
data = data %>% mutate(Rings = log(Rings))

# Start with the full model
M1 = lm(Rings~.,data=data)

# We take a step back model and check if our assumptions are valid:
step.back.aic = step(M1,direction = "backward",trace=FALSE)
drop1(step.back.aic,test="F")
kable(step.back.aic$coefficients)
autoplot(step.back.aic,which=1:2)
```

Taking the log of the rings we see from the qqplot that the shape is much more linear and closer to the 45 degree line. So our normal assumption can hold. However, the residual plot again identifies that non-linearity cannot hold. Checking for the homoskedasticity from the residual plot, the spread of the residuals from the horizontal $y=0$ line is fairly even. 

More importantly, looking at the updated model now, we find that all the variables have been included from the original full model unlike before when length was excluded. We validated this further when taking a step forward model using AIC again:
```{r}
M0 = lm(Rings~1,data=data)
step.fwd.aic=step(M0,scope=list(lower=M0,upper=M1),direction="forward",trace = FALSE)
```

Thus, our final model in predicting the number of rings in an Abalone is:

$\hat{log(Rings)} = \beta_{0} + \beta_{SexI} x_{SexI} + \beta_{SexM} x_{SexM} + \beta_{Length} x_{Length} + \beta_{Diameter} x_{Diameter} + \beta_{Height} x_{Height} + \beta_{WholeWeight} x_{WholeWeight} + \beta_{Shucked Weight} x_{Shucked Weight} + \beta_{VisceraWeight} x_{VisceraWeight} + \beta_{Shell__Weight} x_{ShellWeight}$

```{r}
library(kableExtra)
# Create a table for the coefficients
data.frame(step.back.aic$coefficients) %>% kable(caption = "Values of Beta:") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"),position="center",full_width = F)
```

## K-folds Cross Validation

```{r}
library(caret)
cv_full = train(
  Rings ~ Sex + Length + Diameter + Height + Whole_weight + Shucked_weight + 
    Viscera_weight + Shell_weight,
  data, 
  method = "lm", 
  trControl = trainControl(
    method = "cv", number = 10, verboseIter = FALSE
    )
)
cv_full

cv_simple = train(
  Rings ~ Sex + Diameter + Height + Whole_weight + Shucked_weight + 
    Viscera_weight + Shell_weight, 
  data, 
  method = "lm", 
  trControl = trainControl(
    method = "cv", number = 10, verboseIter = FALSE
    )
)
cv_simple

ggpairs(data, aes(colour = Sex, alpha = 0.8), title="Pairs plot for abalone dataset") + theme_grey(base_size = 8)


```


## Infant Model
```{r}
data.infant = data
data.infant = data.infant %>% mutate(Sex = case_when(Sex == "F" ~ "NI", Sex == "M" ~ "NI", Sex == "I" ~ "I"))

cv_full = train(
  Rings ~ Sex + Length + Diameter + Height + Whole_weight + Shucked_weight + 
    Viscera_weight + Shell_weight,
  data.infant, 
  method = "lm", 
  trControl = trainControl(
    method = "cv", number = 10, verboseIter = FALSE
    )
)
cv_full

cv_simple = train(
  Rings ~ Sex + Diameter + Height + Whole_weight + Shucked_weight + 
    Viscera_weight + Shell_weight, 
  data.infant, 
  method = "lm", 
  trControl = trainControl(
    method = "cv", number = 10, verboseIter = FALSE
    )
)
cv_simple
```
In the infant model, we combined male and female abalone into the category NI(non-infant), while keeping infants as I.

We observe a slightly higher p-value.

The full model and the simple model both give around the same RMSE and MAE, which indicates that simplifying our model did not negatively impact the accuracy of our prediction.

## Exhaustive Search
```{r}
library(leaps)
regsubset.out = regsubsets(Rings ~ . , data = data, method = "exhaustive")
regsubset.summary = summary(regsubset.out)
plot(regsubset.summary$rsq, xlab = "Number of Variables", ylab = "R Square", type = "b")
plot(regsubset.summary$cp, xlab = "Number of Variables", ylab = "Mallow's Cp", type = "b")
plot(regsubset.out, scale = "Cp")
```
Maybe combining sex into infant/noninfant would be better model? And can also look at removing Length from the model.


## Results
<!-- Provide inferences about the questions of interest. -->


## Discussion and Conclusion
<!-- Describe any limitations of your analysis and how they might be overcome in future research and provide brief conclusions about the results of your study. -->

## References

Warwick J Nash, Tracy L Sellers, Simon R Talbot, Andrew J Cawthorn and Wes B Ford (1994) "The Population Biology of Abalone (_Haliotis_ species) in Tasmania. I. Blacklip Abalone (_H. rubra_) from the North Coast and Islands of Bass Strait", Sea Fisheries Division, Technical Report No. 48 (ISSN 1034-3288), accessed via URL:
https://archive.ics.uci.edu/ml/datasets/abalone

